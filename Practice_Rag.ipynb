{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b336d005-0d77-4949-8198-eca627ca1d5f",
   "metadata": {},
   "source": [
    "# 1. ì»¤ë„/í™˜ê²½ ì ê²€ & ê¸°ë³¸ ê²½ë¡œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0b651ea-4d17-46cc-93e6-b7bfe08833e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]\n",
      "Platform: Windows-10-10.0.19045-SP0\n",
      "Venv: C:\\Users\\user\\Practice_Rag\\venv\n",
      "CWD: C:\\Users\\user\\Practice_Rag\\Python_code\n",
      "DATA_DIR: C:\\Users\\user\\Practice_Rag\\Python_code\\data\n"
     ]
    }
   ],
   "source": [
    "import sys, os, platform, subprocess, textwrap\n",
    "\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"Platform:\", platform.platform())\n",
    "print(\"Venv:\", os.environ.get(\"VIRTUAL_ENV\"))\n",
    "print(\"CWD:\", os.getcwd())\n",
    "\n",
    "# í”„ë¡œì íŠ¸ í´ë”ì— data í´ë” ì—†ìœ¼ë©´ ìƒì„±\n",
    "DATA_DIR = os.path.join(os.getcwd(), \"data\")\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "print(\"DATA_DIR:\", DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad370bd2-818e-426f-8076-af42a59eae66",
   "metadata": {},
   "source": [
    "# 2. í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ (RAG ê¸°ë³¸)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4ac2281-5aa7-4844-b05c-de50179e25bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Practice_Rag\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.5.1+cu121 | CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 2060\n"
     ]
    }
   ],
   "source": [
    "# ì„í¬íŠ¸\n",
    "import re, glob, json\n",
    "from typing import List, Dict\n",
    "import numpy as np\n",
    "\n",
    "# ì„ë² ë”©/í† ì¹˜\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# ë²¡í„° ì¸ë±ìŠ¤(FAISS)\n",
    "import faiss\n",
    "\n",
    "# íŒŒì¼ íŒŒì‹±(ê°€ë²¼ìš´ ê²½ë¡œ: PDFëŠ” pypdf, í…ìŠ¤íŠ¸ëŠ” open)\n",
    "from pypdf import PdfReader\n",
    "\n",
    "print(\"Torch:\", torch.__version__, \"| CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bf9d1e-57ba-4ba1-88cb-060cc2719c1e",
   "metadata": {},
   "source": [
    "# 3. (ì„ íƒ) OpenAI í´ë¼ì´ì–¸íŠ¸ ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcce5129-15c6-4ad9-b213-344d021a6b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI key loaded: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# ì•ˆì „: í„°ë¯¸ë„ì—ì„œ ë¯¸ë¦¬ ì„¤ì •í–ˆë‹¤ë©´ ì´ ì…€ì€ ìƒëµ ê°€ëŠ¥\n",
    "# ì˜ˆ) í„°ë¯¸ë„: setx OPENAI_API_KEY \"sk-XXXX\"  (ìƒˆ ì„¸ì…˜ë¶€í„° ë°˜ì˜)\n",
    "# ë…¸íŠ¸ë¶ ì„ì‹œ ì„¤ì •: (ì‹¤ì„œë¹„ìŠ¤/ë²„ì „ê´€ë¦¬ì—ëŠ” ë„£ì§€ ë§ˆì„¸ìš”!)\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "print(\"OpenAI key loaded:\", bool(os.getenv(\"OPENAI_API_KEY\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd029e2-3f41-4d50-b5b2-7be649b9cb4d",
   "metadata": {},
   "source": [
    "# 4. ë°ì´í„° ê°€ì ¸ì˜¤ê¸° + ë¬¸ì„œ ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "890943e6-848e-448f-9a2c-a69643560cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60b904db-3973-4cb5-90bf-1fe6340b5f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../Data'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = '../Data' # .. ì€ í´ë” ë’¤ë¡œê°€ê¸°\n",
    "folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70dd84e5-4b73-4a3b-996f-763d320e2700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ë³´ì´ìŠ¤í”¼ì‹± ì±—ë´‡ ì¦‰ë‹µí˜• ì‹œë‚˜ë¦¬ì˜¤ ìƒ˜í”Œ.xlsx'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = os.listdir(folder)[0]\n",
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7885dc3-cda5-4ac5-9b5c-5a5cd4ff11ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../Data\\\\ë³´ì´ìŠ¤í”¼ì‹± ì±—ë´‡ ì¦‰ë‹µí˜• ì‹œë‚˜ë¦¬ì˜¤ ìƒ˜í”Œ.xlsx'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = os.path.join(folder, file_name)\n",
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "447d8179-8155-4a04-b465-8086d2c6c16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(file_path, sheet_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6aeac77b-3af2-40d6-8725-f190612c1015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ì „í™” 1ì°¨', 'ë¬¸ì 2ì°¨', 'ë‹¨ìˆœìƒë‹´ 1ì°¨']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sheets = list(data.keys())\n",
    "Sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "33c53f1d-50f9-44a9-b9c2-90130fe3d537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ ë§Œë“¤ê¸°\n",
    "docs = []\n",
    "for sheet in Sheets :\n",
    "    df = data[sheet].copy()\n",
    "    df = df[['ë¬¸ì˜ë‚´ìš©', 'ë‹µë³€ë‚´ìš©']]\n",
    "    df.loc[:, 'ì¶œì²˜'] = sheet\n",
    "    for _, row in df.iterrows():\n",
    "        doc = {\n",
    "            \"text\": str(row[\"ë¬¸ì˜ë‚´ìš©\"]),  # ì„ë² ë”©í•  ë³¸ë¬¸\n",
    "            \"metadata\": {\n",
    "                \"ë‹µë³€ë‚´ìš©\": str(row[\"ë‹µë³€ë‚´ìš©\"]),\n",
    "                \"ì¶œì²˜\": str(row[\"ì¶œì²˜\"])\n",
    "            }\n",
    "        }\n",
    "        docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9feb60fd-76f2-4b99-88b9-1c6e7ee61659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a79034-774f-4a39-aef3-bcb46eaa5511",
   "metadata": {},
   "source": [
    "# 5. í…ìŠ¤íŠ¸ ì„ë² ë”© í•˜ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d43cd6c-1c04-4a3e-8ac7-74c5e2f42263",
   "metadata": {},
   "source": [
    "## 0. í™˜ê²½ í™•ì¸ & ì¥ì¹˜ ì„ íƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "80755155-161f-45b5-9778-c87ea65fa2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.10.7\n",
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 2060\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys, json, time\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b124e6-00ad-4f23-9d42-94c857d9eb20",
   "metadata": {},
   "source": [
    "## 1. docs â†’ LangChain Documents ë³€í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d4b19611-9fe4-4d97-80c4-75270d01fc1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126,\n",
       " Document(metadata={'ë‹µë³€ë‚´ìš©': 'ëŒ€í™˜ëŒ€ì¶œì´ ê°€ëŠ¥í•˜ë‹¤ê³  í•˜ë©´ì„œ ê¸°ì¡´ ëŒ€ì¶œê¸ˆ ìƒí™˜ì„ ìœ ë„ í•œ í›„ ê°€ë¡œì±„ëŠ” í”¼ì‹± ìœ í˜•ì…ë‹ˆë‹¤. ê¸°ì¡´ ëŒ€ì¶œì²˜ì¸ ì‹ í•œì¹´ë“œ(â˜ 1544-7000)ë¡œ ìƒí™˜ê´€ë ¨ ë‚´ìš©ì— ëŒ€í•´ ì§„ìœ„ì—¬ë¶€ í™•ì¸ì„ í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\\në‹¨ìˆœ í†µí™”ê°€ ì•„ë‹Œ ê°œì¸ì •ë³´ ë…¸ì¶œì´ ìˆëŠ” ê²½ìš°ì—ëŠ” ëª…ì˜ë„ìš© í”¼í•´ ì˜ˆë°©ë²•ìœ¼ë¡œ ì¡°ì¹˜í•˜ì…”ì„œ 2ì°¨ í”¼í•´ë¥¼ ì˜ˆë°©í•´ì•¼ í•©ë‹ˆë‹¤.', 'ì¶œì²˜': 'ì „í™” 1ì°¨'}, page_content='OKê¸ˆìœµ ë‹´ë‹¹ìì™€ ì „í™”ë¡œ ëŒ€ì¶œìƒë‹´ì„ í–ˆëŠ”ë° ì´í›„ ê¸°ì¡´ ëŒ€ì¶œì´ ìˆëŠ” ì‹ í•œì¹´ë“œ ë‹´ë‹¹ìí•œí…Œì„œ ê³„ì•½ìœ„ë°˜ì„ í–ˆìœ¼ë‹ˆ ê¸°ì¡´ ëŒ€ì¶œê¸ˆì„ ëŒ€ë©´ìƒí™˜ í•´ì•¼ í•œë‹¤ë©´ì„œ  í•´ì§€í†µë³´ì„œ ë° ì§€ê¸‰ì •ì§€í†µë³´ì„œë¥¼ ë³´ë‚´ì™”ì–´ìš”'))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.docstore.document import Document\n",
    "documents = [\n",
    "    Document(page_content=d[\"text\"], metadata=d[\"metadata\"])\n",
    "    for d in docs\n",
    "]\n",
    "len(documents), documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "23cd3a2b-502d-44c0-9a15-05cde3ac3bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intfloat/multilingual-e5-large"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3618ef32-b947-4329-b05c-981c7b1d1ac9",
   "metadata": {},
   "source": [
    "## 2. E5-large ì„ë² ë”© ì¤€ë¹„ (ì ‘ë‘ì–´ ì„¸íŒ…)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d2ecf7e8-06d3-4c51-a177-d5fbbeae34eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# ë””ë°”ì´ìŠ¤ ì„ íƒ\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class E5Embeddings(HuggingFaceEmbeddings):\n",
    "    \"\"\"E5 ì „ìš©: query/passages ì ‘ë‘ì–´ ìë™ ë¶€ì°© + L2 ì •ê·œí™”\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        # encode_kwargsì—ì„œ normalize_embeddings=True ì„¤ì • (ì½”ì‚¬ì¸ê³¼ ë™ì¹˜)\n",
    "        if \"encode_kwargs\" not in kwargs:\n",
    "            self.encode_kwargs = {\"normalize_embeddings\": True}\n",
    "\n",
    "    def embed_query(self, text: str):\n",
    "        return super().embed_query(f\"query: {text}\")\n",
    "\n",
    "    def embed_documents(self, texts):\n",
    "        texts = [f\"passage: {t}\" for t in texts]\n",
    "        return super().embed_documents(texts)\n",
    "\n",
    "embedding_model = E5Embeddings(\n",
    "    model_name=\"intfloat/multilingual-e5-large\",\n",
    "    model_kwargs={\"device\": device},              # \"cpu\" ê°•ì œ ê°€ëŠ¥\n",
    "    encode_kwargs={\"normalize_embeddings\": True}, # ì•ˆì „í•˜ê²Œ í•œë²ˆ ë” ëª…ì‹œ\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316feb56-ccd7-467f-9376-48c86bfc13b1",
   "metadata": {},
   "source": [
    "## 3. ë²¡í„°ìŠ¤í† ì–´ ìƒì„±/ì €ì¥ (FAISS) /  Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "38d66550-8dca-45ff-a89a-b531508de635",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "try:\n",
    "    from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    from langchain_core.vectorstores import DistanceStrategy  # ì¼ë¶€ ë²„ì „ í˜¸í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "846cd48d-0468-4d49-9177-83c5a1267e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Practice_Rag\\venv\\lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:233: UserWarning: Normalizing L2 is not applicable for metric type: MAX_INNER_PRODUCT\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ì½”ì‚¬ì¸ ìœ ì‚¬ë„: L2 ì •ê·œí™” + ë‚´ì \n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embedding_model,\n",
    "    distance_strategy=DistanceStrategy.MAX_INNER_PRODUCT,\n",
    "    normalize_L2=True,\n",
    ")\n",
    "\n",
    "vectorstore.save_local(\"./faiss_index_voicephishing_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "12fcaa3f-a31f-4d7c-88ee-0f2440a95458",
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = FAISS.load_local(\"./faiss_index_voicephishing_1\",\n",
    "                      embeddings=embedding_model,\n",
    "                      allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfa9b4b-4409-45de-b09d-ba88acf84a7f",
   "metadata": {},
   "source": [
    "## 4. ìœ ì‚¬ë¬¸ì„œ ì°¾ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "00b5f69f-847e-41ab-ae64-545cbc5a4b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] cosine=0.9489 | ì¶œì²˜=ë¬¸ì 2ì°¨\n",
      "ë¬¸ì˜ë‚´ìš©: í•´ì™¸ë°œì‹ ìœ¼ë¡œ ì¹´ë“œê°€ ë°œê¸‰ëë‹¤ëŠ” ë¬¸ìë¥¼ ìˆ˜ì‹ í–ˆëŠ”ë° ë³¸ì¸ì´ ì‹ ì²­í•˜ì§€ ì•Šì•˜ì„ ê²½ìš° ì‚¬ê³ ëŒ€ì‘ì„¼í„°ì— ì „í™”í•˜ë¼ê³  í–ˆì–´ìš” ...\n",
      "ë‹µë³€ë‚´ìš©: ì •ìƒì ì¸ ë°œê¸‰ ë¬¸ìë¼ë©´ ì¹´ë“œì‚¬ ì •ë³´ê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤. ë°œì‹ ë²ˆí˜¸ ë˜ëŠ” ë¬¸ìë‚´ ì•ˆë‚´ì²˜ê°€ ì•„ë‹Œ í•´ë‹¹ ì¹´ë“œì‚¬ì˜ ëŒ€í‘œë²ˆí˜¸ë¡œ ì „í™”ë¥¼ í•˜ì—¬ ë°œê¸‰ ìœ ë¬´ë¥¼ í™•ì¸í•´ì•¼ í•˜ë©°, ì¹´ë“œì‚¬ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°ì—ëŠ” ì „í™”ë¥¼ ìœ ë„í•˜ì—¬ ê°œì¸ì •ë³´ íƒˆì·¨ë¥¼ í•˜ë ¤ëŠ” ë¯¸ë¼ë¬¸ìì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤. \n",
      "ì•ˆë“œë¡œì´ë“œìš© ì‚¬ìš©ìëŠ” ë©”ì‹œì§€ì‹ ê³  > í”¼ì‹±ìœ¼ë¡œ ì‹ ê³  í›„ ë¬¸ì ì‚­ì œë¥¼ í•˜ê³  ë°œì‹ ë²ˆí˜¸ë„ ì°¨ë‹¨ì„ í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤. iOSì‚¬ìš©ìëŠ” ë°œì‹ ë²ˆí˜¸ ì°¨ë‹¨ í›„ ì‚­ì œí•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "--------------------------------------------------------------------------------\n",
      "[2] cosine=0.9190 | ì¶œì²˜=ë¬¸ì 2ì°¨\n",
      "ë¬¸ì˜ë‚´ìš©: í•´ì™¸ë°œì‹ ìœ¼ë¡œ ì¹´ë“œê°€ ë°œê¸‰ëë‹¤ëŠ” ë¬¸ìë¥¼ ìˆ˜ì‹ í–ˆëŠ”ë° ë³¸ì¸ì´ ì‹ ì²­í•˜ì§€ ì•Šì•˜ì„ ê²½ìš° ì „í™”í•˜ë¼ê³  í•´ì„œ í†µí™”í•˜ì—¬ ì¸ì¦ë²ˆí˜¸ë¥¼ ë§í–ˆì–´ìš” ...\n",
      "ë‹µë³€ë‚´ìš©: ë…¸ì¶œëœ ì¸ì¦ë²ˆí˜¸ì˜ ì‚¬ìš©ì²˜ê°€ ì–´ë””ì¸ì§€ì— ë”°ë¼ ê°œì¸ì •ë³´ ë…¸ì¶œ í”¼í•´ ìƒí™©ì´ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ëª…ì˜ë„ìš© ìœ ë¬´ í™•ì¸ë°©ë²• 1ë²ˆ~3ë²ˆê¹Œì§€ ì¡°ì¹˜í•˜ì—¬ íŒŒì•…í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "ë˜í•œ ì¶”í›„ ì¼ì–´ë‚  ìˆ˜ ìˆëŠ” 2ì°¨í”¼í•´ ì˜ˆë°©ì„ ìœ„í•´ ëª…ì˜ë„ìš© ì˜ˆë°©ë²• 1ë²ˆ ~ 4ë²ˆê¹Œì§€ ì¡°ì¹˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "--------------------------------------------------------------------------------\n",
      "[3] cosine=0.9059 | ì¶œì²˜=ë¬¸ì 2ì°¨\n",
      "ë¬¸ì˜ë‚´ìš©: ì¹´ë“œê°€ ë°œê¸‰ë˜ì—ˆë‹¤ëŠ” í•´ì™¸ë°œì‹  ë¬¸ìë¥¼ ìˆ˜ì‹ í–ˆëŠ”ë° ë¬¸ì˜ì‚¬í•­ì´ ìˆìœ¼ë©´ ì „í™”í•˜ë¼ëŠ” ë²ˆí˜¸ê°€ ìˆì–´ìš” ...\n",
      "ë‹µë³€ë‚´ìš©: ì •ìƒì ì¸ ë°œê¸‰ ë¬¸ìë¼ë©´ ì¹´ë“œì‚¬ ì •ë³´ê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤. ë°œì‹ ë²ˆí˜¸ ë˜ëŠ” ë¬¸ìë‚´ ì•ˆë‚´ì²˜ê°€ ì•„ë‹Œ í•´ë‹¹ ì¹´ë“œì‚¬ì˜ ëŒ€í‘œë²ˆí˜¸ë¡œ ì „í™”ë¥¼ í•˜ì—¬ ë°œê¸‰ ìœ ë¬´ë¥¼ í™•ì¸í•´ì•¼ í•˜ë©°, ì¹´ë“œì‚¬ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°ì—ëŠ” ì „í™”ë¥¼ ìœ ë„í•˜ì—¬ ê°œì¸ì •ë³´ íƒˆì·¨ë¥¼ í•˜ë ¤ëŠ” ë¯¸ë¼ë¬¸ìì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤. \n",
      "ì•ˆë“œë¡œì´ë“œìš© ì‚¬ìš©ìëŠ” ë©”ì‹œì§€ì‹ ê³  > í”¼ì‹±ìœ¼ë¡œ ì‹ ê³  í›„ ë¬¸ì ì‚­ì œë¥¼ í•˜ê³  ë°œì‹ ë²ˆí˜¸ë„ ì°¨ë‹¨ì„ í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤. iOSì‚¬ìš©ìëŠ” ë°œì‹ ë²ˆí˜¸ ì°¨ë‹¨ í›„ ì‚­ì œí•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "query = \"í•´ì™¸ë°œì‹ ìœ¼ë¡œ ì¹´ë“œê°€ ë°œê¸‰ëë‹¤ëŠ” ë¬¸ìë¥¼ ìˆ˜ì‹ í–ˆëŠ”ë° ë³¸ì¸ì´ ì‹ ì²­í•˜ì§€ ì•Šì•˜ì„ ê²½ìš° ì‚¬ê³ ëŒ€ì‘ì„¼í„°ì— ì „í™”í•˜ë¼ê³  í–ˆì–´ìš”\"\n",
    "results = vectorstore.similarity_search_with_score(query, k=3)\n",
    "\n",
    "for i, (doc, score) in enumerate(results, 1):\n",
    "    # score âˆˆ [0, 1] (ì •ê·œí™” + ë‚´ì  = ì½”ì‚¬ì¸ìœ ì‚¬ë„)\n",
    "    print(f\"[{i}] cosine={score:.4f} | ì¶œì²˜={doc.metadata.get('ì¶œì²˜')}\")\n",
    "    print(\"ë¬¸ì˜ë‚´ìš©:\", doc.page_content[:160].replace(\"\\n\",\" \"), \"...\")\n",
    "    print(\"ë‹µë³€ë‚´ìš©:\", doc.metadata.get(\"ë‹µë³€ë‚´ìš©\"))\n",
    "    print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e28be64-397c-4dde-a7c9-5a85c95001fe",
   "metadata": {},
   "source": [
    "# 6. OpenAI API + context í•„í„°ë§ ì½”ë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3374d4b7-eb78-4cb9-ad23-66211f353670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í™˜ê²½ë³€ìˆ˜ì— OPENAI_API_KEY ì„¤ì •ë˜ì–´ ìˆì–´ì•¼ í•¨\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b44462ca-8564-492e-92ac-5ec3569c584a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, results, threshold=0.8):\n",
    "    global context\n",
    "    \"\"\"ì½”ì‚¬ì¸ ìœ ì‚¬ë„ threshold ì´ìƒì¸ ë¬¸ì„œë§Œ contextë¡œ í¬í•¨\"\"\"\n",
    "    filtered = [(doc, score) for doc, score in results if score >= threshold]\n",
    "\n",
    "    if not filtered:\n",
    "        return f\"ì‚¬ìš©ì ì§ˆë¬¸: {query}\\n\\nê´€ë ¨ ë¬¸ì„œê°€ ì—†ì–´ ë‹µë³€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "    # context ìƒì„±\n",
    "    context_parts = []\n",
    "    for i, (doc, score) in enumerate(filtered, 1):\n",
    "        context_parts.append(\n",
    "            f\"[{i}] (score={score:.4f}, ì¶œì²˜={doc.metadata.get('ì¶œì²˜')})\\n\"\n",
    "            f\"ë¬¸ì˜ë‚´ìš©: {doc.page_content}\\n\"\n",
    "            f\"ë‹µë³€ë‚´ìš©: {doc.metadata.get('ë‹µë³€ë‚´ìš©')}\\n\"\n",
    "        )\n",
    "\n",
    "    context = \"\\n\\n\".join(context_parts)\n",
    "\n",
    "    # ìµœì¢… í”„ë¡¬í”„íŠ¸\n",
    "    prompt = (\n",
    "        \"ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ë§Œì„ ë°”íƒ•ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ì •í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.\\n\"\n",
    "        \"ì»¨í…ìŠ¤íŠ¸ì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ê³  'ì£¼ì–´ì§„ ìë£Œì— ê·¼ê±°í•´ ì•Œ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'ë¼ê³  ë‹µí•˜ì„¸ìš”.\\n\\n\"\n",
    "        f\"ì‚¬ìš©ì ì§ˆë¬¸:\\n{query}\\n\\n\"\n",
    "        f\"--- ì»¨í…ìŠ¤íŠ¸ (ì½”ì‚¬ì¸â‰¥{threshold}) ---\\n{context}\\n\\n\"\n",
    "        \"ìµœì¢… ë‹µë³€:\"\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "def rag_answer(query, k=3, threshold=0.8, model=\"gpt-4o-mini\"):\n",
    "    # ê²€ìƒ‰\n",
    "    results = vectorstore.similarity_search_with_score(query, k=k)\n",
    "\n",
    "    # í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "    prompt = build_prompt(query, results, threshold=threshold)\n",
    "\n",
    "    # OpenAI API í˜¸ì¶œ\n",
    "    resp = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.2,\n",
    "    )\n",
    "    return resp.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b170538d-0e6a-4f51-8dbd-435e63cd2323",
   "metadata": {},
   "source": [
    "# 7. í…ŒìŠ¤íŠ¸ ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1876aea8-d7e1-42a5-b256-f0cefb066289",
   "metadata": {},
   "source": [
    "## 1. Rag ì‹¤í–‰(open ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8b5f3e98-33d1-421c-b1a9-a26515c70fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì§ˆë¬¸: í•´ì™¸ë°œì‹ ìœ¼ë¡œ ì¹´ë“œê°€ ë°œê¸‰ëë‹¤ëŠ” ë¬¸ìë¥¼ ìˆ˜ì‹ í–ˆëŠ”ë° ë³¸ì¸ì´ ì‹ ì²­í•˜ì§€ ì•Šì•˜ì„ ê²½ìš° ì‚¬ê³ ëŒ€ì‘ì„¼í„°ì— ì „í™”í•˜ë¼ê³  í–ˆì–´ìš”\n",
      "\n",
      "[ìƒì„±ëœ ë‹µë³€]\n",
      " í•´ì™¸ë°œì‹ ìœ¼ë¡œ ì¹´ë“œê°€ ë°œê¸‰ëë‹¤ëŠ” ë¬¸ìë¥¼ ìˆ˜ì‹ í–ˆì§€ë§Œ ë³¸ì¸ì´ ì‹ ì²­í•˜ì§€ ì•Šì•˜ë‹¤ë©´, í•´ë‹¹ ì¹´ë“œì‚¬ì˜ ëŒ€í‘œë²ˆí˜¸ë¡œ ì „í™”ë¥¼ í•˜ì—¬ ë°œê¸‰ ìœ ë¬´ë¥¼ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤. ë°œì‹ ë²ˆí˜¸ë‚˜ ë¬¸ì ë‚´ ì•ˆë‚´ì²˜ê°€ ì•„ë‹Œ ì¹´ë“œì‚¬ì˜ ê³µì‹ ë²ˆí˜¸ë¡œ í™•ì¸í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ë§Œì•½ ì¹´ë“œì‚¬ ì •ë³´ê°€ ì—†ë‹¤ë©´, ì´ëŠ” ê°œì¸ì •ë³´ íƒˆì·¨ë¥¼ ì‹œë„í•˜ëŠ” ë¯¸ë¼ë¬¸ìì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤. ì•ˆë“œë¡œì´ë“œ ì‚¬ìš©ìëŠ” ë©”ì‹œì§€ ì‹ ê³ ë¥¼ í†µí•´ í”¼ì‹±ìœ¼ë¡œ ì‹ ê³ í•œ í›„ ë¬¸ìë¥¼ ì‚­ì œí•˜ê³  ë°œì‹ ë²ˆí˜¸ë¥¼ ì°¨ë‹¨í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤. iOS ì‚¬ìš©ìëŠ” ë°œì‹ ë²ˆí˜¸ë¥¼ ì°¨ë‹¨í•œ í›„ ì‚­ì œí•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "[ì¶œì²˜]\n",
      " [1] (score=0.9489, ì¶œì²˜=ë¬¸ì 2ì°¨)\n",
      "ë¬¸ì˜ë‚´ìš©: í•´ì™¸ë°œì‹ ìœ¼ë¡œ ì¹´ë“œê°€ ë°œê¸‰ëë‹¤ëŠ” ë¬¸ìë¥¼ ìˆ˜ì‹ í–ˆëŠ”ë° ë³¸ì¸ì´ ì‹ ì²­í•˜ì§€ ì•Šì•˜ì„ ê²½ìš° ì‚¬ê³ ëŒ€ì‘ì„¼í„°ì— ì „í™”í•˜ë¼ê³  í–ˆì–´ìš”\n",
      "ë‹µë³€ë‚´ìš©: ì •ìƒì ì¸ ë°œê¸‰ ë¬¸ìë¼ë©´ ì¹´ë“œì‚¬ ì •ë³´ê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤. ë°œì‹ ë²ˆí˜¸ ë˜ëŠ” ë¬¸ìë‚´ ì•ˆë‚´ì²˜ê°€ ì•„ë‹Œ í•´ë‹¹ ì¹´ë“œì‚¬ì˜ ëŒ€í‘œë²ˆí˜¸ë¡œ ì „í™”ë¥¼ í•˜ì—¬ ë°œê¸‰ ìœ ë¬´ë¥¼ í™•ì¸í•´ì•¼ í•˜ë©°, ì¹´ë“œì‚¬ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°ì—ëŠ” ì „í™”ë¥¼ ìœ ë„í•˜ì—¬ ê°œì¸ì •ë³´ íƒˆì·¨ë¥¼ í•˜ë ¤ëŠ” ë¯¸ë¼ë¬¸ìì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤. \n",
      "ì•ˆë“œë¡œì´ë“œìš© ì‚¬ìš©ìëŠ” ë©”ì‹œì§€ì‹ ê³  > í”¼ì‹±ìœ¼ë¡œ ì‹ ê³  í›„ ë¬¸ì ì‚­ì œë¥¼ í•˜ê³  ë°œì‹ ë²ˆí˜¸ë„ ì°¨ë‹¨ì„ í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤. iOSì‚¬ìš©ìëŠ” ë°œì‹ ë²ˆí˜¸ ì°¨ë‹¨ í›„ ì‚­ì œí•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "\n",
      "[2] (score=0.9190, ì¶œì²˜=ë¬¸ì 2ì°¨)\n",
      "ë¬¸ì˜ë‚´ìš©: í•´ì™¸ë°œì‹ ìœ¼ë¡œ ì¹´ë“œê°€ ë°œê¸‰ëë‹¤ëŠ” ë¬¸ìë¥¼ ìˆ˜ì‹ í–ˆëŠ”ë° ë³¸ì¸ì´ ì‹ ì²­í•˜ì§€ ì•Šì•˜ì„ ê²½ìš° ì „í™”í•˜ë¼ê³  í•´ì„œ í†µí™”í•˜ì—¬ ì¸ì¦ë²ˆí˜¸ë¥¼ ë§í–ˆì–´ìš”\n",
      "ë‹µë³€ë‚´ìš©: ë…¸ì¶œëœ ì¸ì¦ë²ˆí˜¸ì˜ ì‚¬ìš©ì²˜ê°€ ì–´ë””ì¸ì§€ì— ë”°ë¼ ê°œì¸ì •ë³´ ë…¸ì¶œ í”¼í•´ ìƒí™©ì´ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ëª…ì˜ë„ìš© ìœ ë¬´ í™•ì¸ë°©ë²• 1ë²ˆ~3ë²ˆê¹Œì§€ ì¡°ì¹˜í•˜ì—¬ íŒŒì•…í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "ë˜í•œ ì¶”í›„ ì¼ì–´ë‚  ìˆ˜ ìˆëŠ” 2ì°¨í”¼í•´ ì˜ˆë°©ì„ ìœ„í•´ ëª…ì˜ë„ìš© ì˜ˆë°©ë²• 1ë²ˆ ~ 4ë²ˆê¹Œì§€ ì¡°ì¹˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "\n",
      "[3] (score=0.9059, ì¶œì²˜=ë¬¸ì 2ì°¨)\n",
      "ë¬¸ì˜ë‚´ìš©: ì¹´ë“œê°€ ë°œê¸‰ë˜ì—ˆë‹¤ëŠ” í•´ì™¸ë°œì‹  ë¬¸ìë¥¼ ìˆ˜ì‹ í–ˆëŠ”ë° ë¬¸ì˜ì‚¬í•­ì´ ìˆìœ¼ë©´ ì „í™”í•˜ë¼ëŠ” ë²ˆí˜¸ê°€ ìˆì–´ìš”\n",
      "ë‹µë³€ë‚´ìš©: ì •ìƒì ì¸ ë°œê¸‰ ë¬¸ìë¼ë©´ ì¹´ë“œì‚¬ ì •ë³´ê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤. ë°œì‹ ë²ˆí˜¸ ë˜ëŠ” ë¬¸ìë‚´ ì•ˆë‚´ì²˜ê°€ ì•„ë‹Œ í•´ë‹¹ ì¹´ë“œì‚¬ì˜ ëŒ€í‘œë²ˆí˜¸ë¡œ ì „í™”ë¥¼ í•˜ì—¬ ë°œê¸‰ ìœ ë¬´ë¥¼ í™•ì¸í•´ì•¼ í•˜ë©°, ì¹´ë“œì‚¬ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°ì—ëŠ” ì „í™”ë¥¼ ìœ ë„í•˜ì—¬ ê°œì¸ì •ë³´ íƒˆì·¨ë¥¼ í•˜ë ¤ëŠ” ë¯¸ë¼ë¬¸ìì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤. \n",
      "ì•ˆë“œë¡œì´ë“œìš© ì‚¬ìš©ìëŠ” ë©”ì‹œì§€ì‹ ê³  > í”¼ì‹±ìœ¼ë¡œ ì‹ ê³  í›„ ë¬¸ì ì‚­ì œë¥¼ í•˜ê³  ë°œì‹ ë²ˆí˜¸ë„ ì°¨ë‹¨ì„ í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤. iOSì‚¬ìš©ìëŠ” ë°œì‹ ë²ˆí˜¸ ì°¨ë‹¨ í›„ ì‚­ì œí•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "query = \"í•´ì™¸ë°œì‹ ìœ¼ë¡œ ì¹´ë“œê°€ ë°œê¸‰ëë‹¤ëŠ” ë¬¸ìë¥¼ ìˆ˜ì‹ í–ˆëŠ”ë° ë³¸ì¸ì´ ì‹ ì²­í•˜ì§€ ì•Šì•˜ì„ ê²½ìš° ì‚¬ê³ ëŒ€ì‘ì„¼í„°ì— ì „í™”í•˜ë¼ê³  í–ˆì–´ìš”\"\n",
    "answer = rag_answer(query, k=3, threshold=0.8)\n",
    "print(\"ì§ˆë¬¸:\", query)\n",
    "print(\"\\n[ìƒì„±ëœ ë‹µë³€]\\n\", answer)\n",
    "print(\"\\n[ì¶œì²˜]\\n\", context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc2ac06-78cc-48bf-ac60-908c9340f745",
   "metadata": {},
   "source": [
    "## 2. ê·¸ëƒ¥ LLM ì´ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "874071b7-924a-4eed-a7f3-69d1fdc22a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'í•´ì™¸ë°œì‹ ìœ¼ë¡œ ì¹´ë“œê°€ ë°œê¸‰ëë‹¤ëŠ” ë¬¸ìë¥¼ ìˆ˜ì‹ í–ˆëŠ”ë° ë³¸ì¸ì´ ì‹ ì²­í•˜ì§€ ì•Šì•˜ì„ ê²½ìš° ì‚¬ê³ ëŒ€ì‘ì„¼í„°ì— ì „í™”í•˜ë¼ê³  í–ˆì–´ìš”'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7d148ed7-5b4d-482d-85de-e494a8a5ca80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì§ˆë¬¸: í•´ì™¸ë°œì‹ ìœ¼ë¡œ ì¹´ë“œê°€ ë°œê¸‰ëë‹¤ëŠ” ë¬¸ìë¥¼ ìˆ˜ì‹ í–ˆëŠ”ë° ë³¸ì¸ì´ ì‹ ì²­í•˜ì§€ ì•Šì•˜ì„ ê²½ìš° ì‚¬ê³ ëŒ€ì‘ì„¼í„°ì— ì „í™”í•˜ë¼ê³  í–ˆì–´ìš”\n",
      "\n",
      "[LLM ë‹µë³€]\n",
      " í•´ì™¸ ë°œì‹ ìœ¼ë¡œ ì¹´ë“œê°€ ë°œê¸‰ë˜ì—ˆë‹¤ëŠ” ë¬¸ìë¥¼ ë°›ì•˜ê³ , ë³¸ì¸ì´ ì‹ ì²­í•˜ì§€ ì•Šì•˜ë‹¤ë©´ ë§¤ìš° ì£¼ì˜í•´ì•¼ í•©ë‹ˆë‹¤. ì´ëŸ° ê²½ìš° ì‚¬ê¸°ë‚˜ í•´í‚¹ì˜ ìœ„í—˜ì´ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì¦‰ì‹œ ë‹¤ìŒê³¼ ê°™ì€ ì¡°ì¹˜ë¥¼ ì·¨í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **ì‚¬ê³ ëŒ€ì‘ì„¼í„°ì— ì—°ë½í•˜ê¸°**: í•´ë‹¹ ì¹´ë“œì‚¬ì˜ ì‚¬ê³ ëŒ€ì‘ì„¼í„°ì— ì¦‰ì‹œ ì „í™”í•˜ì—¬ ìƒí™©ì„ ì„¤ëª…í•˜ê³ , ì¹´ë“œ ë°œê¸‰ì— ëŒ€í•œ í™•ì¸ì„ ìš”ì²­í•˜ì„¸ìš”. ì¹´ë“œì‚¬ì—ì„œëŠ” ì¶”ê°€ì ì¸ ì¡°ì¹˜ë¥¼ ì•ˆë‚´í•´ ì¤„ ê²ƒì…ë‹ˆë‹¤.\n",
      "\n",
      "2. **ì¹´ë“œ ì‚¬ìš© ë‚´ì—­ í™•ì¸**: ë§Œì•½ ì¹´ë“œê°€ ì´ë¯¸ ë°œê¸‰ë˜ì—ˆë‹¤ë©´, ê·¸ ì¹´ë“œë¡œì˜ ì‚¬ìš© ë‚´ì—­ì„ í™•ì¸í•˜ì—¬ ë³¸ì¸ì´ ëª¨ë¥´ëŠ” ê±°ë˜ê°€ ìˆëŠ”ì§€ ì²´í¬í•˜ì„¸ìš”.\n",
      "\n",
      "3. **ì‹ ë¶„ í™•ì¸**: ì¹´ë“œì‚¬ì— ì—°ë½í•  ë•Œ, ë³¸ì¸ì˜ ì‹ ë¶„ì„ í™•ì¸í•  ìˆ˜ ìˆëŠ” ì •ë³´ë¥¼ ë¯¸ë¦¬ ì¤€ë¹„í•˜ì„¸ìš”. ê°œì¸ ì •ë³´ê°€ ìœ ì¶œëœ ê²½ìš° ì¶”ê°€ì ì¸ í”¼í•´ë¥¼ ë°©ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "4. **ì‹ ìš©ì •ë³´ ì¡°íšŒ**: ì‹ ìš©ì •ë³´ë¥¼ ì¡°íšŒí•˜ì—¬ ë³¸ì¸ì˜ ì‹ ìš©ì¹´ë“œë‚˜ ëŒ€ì¶œì— ì´ìƒì´ ì—†ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\n",
      "\n",
      "5. **ë¹„ë°€ë²ˆí˜¸ ë° ë³´ì•ˆ ì •ë³´ ë³€ê²½**: ë§Œì•½ ì¹´ë“œ ì •ë³´ê°€ ìœ ì¶œë˜ì—ˆë‹¤ê³  ì˜ì‹¬ëœë‹¤ë©´, ê´€ë ¨ëœ ëª¨ë“  ê³„ì •ì˜ ë¹„ë°€ë²ˆí˜¸ì™€ ë³´ì•ˆ ì •ë³´ë¥¼ ë³€ê²½í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.\n",
      "\n",
      "6. **ì‚¬ê¸° ì‹ ê³ **: í•„ìš”ì‹œ ê²½ì°°ì— ì‚¬ê¸° ì‹ ê³ ë¥¼ ê³ ë ¤í•˜ì„¸ìš”.\n",
      "\n",
      "ì´ëŸ° ìƒí™©ì—ì„œëŠ” ì‹ ì†í•˜ê²Œ ëŒ€ì‘í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "def answer_only_with_query(query, model=\"gpt-4o-mini\"):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": query}],\n",
    "        temperature=0.7,   # ë‹¤ì–‘ì„± ì •ë„ (0=ì‚¬ì‹¤ì , 1=ì°½ì˜ì )\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "# query = \"í•´ì™¸ë°œì‹ ìœ¼ë¡œ ì¹´ë“œê°€ ë°œê¸‰ëë‹¤ëŠ” ë¬¸ìë¥¼ ìˆ˜ì‹ í–ˆëŠ”ë° ë³¸ì¸ì´ ì‹ ì²­í•˜ì§€ ì•Šì•˜ì„ ê²½ìš° ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?\"\n",
    "answer = answer_only_with_query(query)\n",
    "print(\"ì§ˆë¬¸:\", query)\n",
    "print(\"\\n[LLM ë‹µë³€]\\n\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab708ae0-eee6-4e20-8946-49901a3727b8",
   "metadata": {},
   "source": [
    "## 3. Ollama + Gemma7b (q4) RAG í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4a3b6866-a918-46f5-9992-43f63c9d753c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•´ì™¸ë°œì‹ ìœ¼ë¡œ ì¹´ë“œê°€ ë°œê¸‰ëë‹¤ëŠ” ë¬¸ìë¥¼ ìˆ˜ì‹ í–ˆëŠ”ë° ë³¸ì¸ì´ ì‹ ì²­í•˜ì§€ ì•Šì•˜ì„ ê²½ìš°, ë‹¤ìŒê³¼ ê°™ì€ ê³¼ì •ì„ ê±°ì³ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "**1. ì¹´ë“œì‚¬ í™•ì¸:**\n",
      "\n",
      "* ì •ìƒì ì¸ ë°œê¸‰ ë¬¸ìë¼ë©´ ì¹´ë“œì‚¬ ì •ë³´ê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\n",
      "* ë°œì‹ ë²ˆí˜¸ ë˜ëŠ” ë¬¸ìë‚´ ì•ˆë‚´ì²˜ê°€ ì•„ë‹Œ í•´ë‹¹ ì¹´ë“œì‚¬ì˜ ëŒ€í‘œë²ˆí˜¸ë¡œ ì „í™”ë¥¼ í•˜ì—¬ ë°œê¸‰ ìœ ë¬´ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n",
      "* ì¹´ë“œì‚¬ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°ì—ëŠ” ì „í™”ë¥¼ ìœ ë„í•˜ì—¬ ê°œì¸ì •ë³´ íƒˆì·¨ë¥¼ í•˜ë ¤ëŠ” ë¯¸ë¼ë¬¸ìì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.\n",
      "\n",
      "**2. í”¼í•´ ì˜ˆë°©:**\n",
      "\n",
      "* ì•ˆë“œë¡œì´ë“œìš© ì‚¬ìš©ìëŠ” ë©”ì‹œì§€ì‹ ê³  > í”¼ì‹±ìœ¼ë¡œ ì‹ ê³  í›„ ë¬¸ì ì‚­ì œë¥¼ í•˜ê³  ë°œì‹ ë²ˆí˜¸ë„ ì°¨ë‹¨ì„ í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "* iOSì‚¬ìš©ìëŠ” ë°œì‹ ë²ˆí˜¸ ì°¨ë‹¨ í›„ ì‚­ì œí•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "* ëª…ì˜ë„ìš© ìœ ë¬´ í™•ì¸ë°©ë²• 1ë²ˆ~3ë²ˆê¹Œì§€ ì¡°ì¹˜í•˜ì—¬ íŒŒì•…í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "* ì¶”í›„ ì¼ì–´ë‚  ìˆ˜ ìˆëŠ” 2ì°¨í”¼í•´ ì˜ˆë°©ì„ ìœ„í•´ ëª…ì˜ë„ìš© ì˜ˆë°©ë²• 1ë²ˆ ~ 4ë²ˆê¹Œì§€ ì¡°ì¹˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "**3. í•´ê²°:**\n",
      "\n",
      "* í•´ì™¸ì—ì„œ ì¹´ë“œ ê²°ì œ ë‚´ì—­ì´ ìˆë‹¤ëŠ” ë¬¸ìë¥¼ ìˆ˜ì‹ í•˜ì˜€ìŠµë‹ˆë‹¤. ë³¸ì¸ì´ ê²°ì œí•œ ê²ƒì´ ì•„ë‹ ê²½ìš° ì „í™”í•˜ë¼ëŠ” ê³³ì´ ìˆì–´ ì „í™” í–ˆëŠ”ë° ì´í›„ ê¸ˆê°ì›ê³¼ ê²€ì°°ì²­ì—ì„œ ì „í™”ë¥¼ ë°›ì•˜ìŠµë‹ˆë‹¤.\n",
      "* ë¬¸ìì— í¬í•¨ëœ ì „í™”ë²ˆí˜¸ë¡œ ì—°ë½í•˜ê²Œ í•˜ì—¬ ê°œì¸ì •ë³´ë¥¼ íƒˆì·¨í•˜ê±°ë‚˜ ì•…ì„±íŒŒì¼, ì›ê²©ì œì–´ì•± ì‹¤í–‰ì„ ìœ ë„í•˜ëŠ” í˜•ì‹ì˜ ë³´ì´ìŠ¤í”¼ì‹±ì…ë‹ˆë‹¤.\n",
      "* í˜„ì¬ ê²€ì°°ì²­, ê¸ˆê°ì› ë“±ì˜ ê³µê³µê¸°ê´€ ëŒ€í‘œë²ˆí˜¸ë¡œ ì „í™”ë¥¼ ìˆ˜ì‹ í•˜ê³  ì†Œì† ê³µë¬´ì›ì„ ì‚¬ì¹­í•˜ëŠ” ì „í™”ë¥¼ ë°›ìœ¼ì…¨ë‹¤ë©´ ì´ë¯¸ íœ´ëŒ€í°ì€ ì›ê²©ì œì–´ ë° ì•…ì„±ì•±ì˜ ì˜í–¥ì„ ë°›ì•„ ì •ìƒì ì¸ ì „í™”ë¥¼ ìˆ˜ì‹ , ë°œì‹ í•  ìˆ˜ ìˆëŠ” ìƒíƒœê°€ ì•„ë‹ˆë¯€ë¡œ ì‹ ì†íˆ íœ´ëŒ€í°ì„ ë¹„í–‰ê¸°ëª¨ë“œ ë° ë°ì´í„°ì°¨ë‹¨, ì™€ì´íŒŒì´ ì°¨ë‹¨ ëª¨ë“œë¡œ ì „í™˜í•˜ì‹œê³  ì•…ì„±ì„¤ì¹˜íŒŒì¼(.apk) ìœ ë¬´ë¥¼ í™•ì¸ ë° ì‚­ì œ, ëª¨ë°”ì¼ ë°±ì‹  ê²€ì‚¬ë¥¼ í•´ì•¼ í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def ollama_generate(model: str, prompt: str, temperature: float = 0.2) -> str:\n",
    "    \"\"\"Ollama ë¡œì»¬ ëª¨ë¸ í˜¸ì¶œ (REST API)\"\"\"\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False,   # í•œ ë²ˆì— ì‘ë‹µ ë°›ê¸°\n",
    "        \"options\": {\"temperature\": temperature},\n",
    "    }\n",
    "    r = requests.post(url, json=payload, timeout=600)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "    return data.get(\"response\", \"\").strip()\n",
    "\n",
    "def rag_answer_ollama(query, k=3, threshold=0.8, \n",
    "                      model=\"gemma:7b-instruct-q4_K_M\", temperature=0.2):\n",
    "    # 1) ë²¡í„° ê²€ìƒ‰\n",
    "    results = vectorstore.similarity_search_with_score(query, k=k)\n",
    "\n",
    "    # 2) í”„ë¡¬í”„íŠ¸ ë§Œë“¤ê¸° (ê¸°ì¡´ build_prompt í•¨ìˆ˜ ì‚¬ìš©)\n",
    "    prompt = build_prompt(query, results, threshold=threshold)\n",
    "\n",
    "    # 3) Ollama í˜¸ì¶œ\n",
    "    answer = ollama_generate(model=model, prompt=prompt, temperature=temperature)\n",
    "    return answer\n",
    "\n",
    "# ğŸ”¹ í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "query = \"í•´ì™¸ë°œì‹ ìœ¼ë¡œ ì¹´ë“œê°€ ë°œê¸‰ëë‹¤ëŠ” ë¬¸ìë¥¼ ìˆ˜ì‹ í–ˆëŠ”ë° ë³¸ì¸ì´ ì‹ ì²­í•˜ì§€ ì•Šì•˜ì„ ê²½ìš° ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?\"\n",
    "print(rag_answer_ollama(query, k=5, threshold=0.8, model=\"gemma:7b-instruct-q4_K_M\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84000e8-aa50-4281-b573-ee12af7e2bf0",
   "metadata": {},
   "source": [
    "## 4. LangChain + ChatOllama RAG í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "df200abc-a9d7-472a-8131-04bd2471dcc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_22412\\1210812642.py:5: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  chat_llm = ChatOllama(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ë‹µë³€]\n",
      " í•´ì™¸ë°œì‹ ìœ¼ë¡œ ì¹´ë“œê°€ ë°œê¸‰ëë‹¤ëŠ” ë¬¸ìë¥¼ ìˆ˜ì‹ í–ˆëŠ”ë° ë³¸ì¸ì´ ì‹ ì²­í•˜ì§€ ì•Šì•˜ì„ ê²½ìš°ì—ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ê³¼ì •ì„ ê±°ë™í•©ë‹ˆë‹¤.\n",
      "\n",
      "**1. ì¹´ë“œì‚¬ ì •ë³´ í™•ì¸:**\n",
      "\n",
      "* ë¬¸ìì— í¬í•¨ëœ ì¹´ë“œì‚¬ ì •ë³´ê°€ ì •í™•í•œì§€ í™•ì¸í•©ë‹ˆë‹¤.\n",
      "* ë°œì‹ ë²ˆí˜¸ ë˜ëŠ” ë¬¸ìë‚´ ì•ˆë‚´ì²˜ê°€ ì•„ë‹Œ í•´ë‹¹ ì¹´ë“œì‚¬ì˜ ëŒ€í‘œë²ˆí˜¸ë¡œ ì „í™”ë¥¼ í•˜ì—¬ ë°œê¸‰ ìœ ë¬´ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n",
      "* ì¹´ë“œì‚¬ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°ì—ëŠ” ì „í™”ë¥¼ ìœ ë„í•˜ì—¬ ê°œì¸ì •ë³´ íƒˆì·¨ë¥¼ í•˜ë ¤ëŠ” ë¯¸ë¼ë¬¸ìì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.\n",
      "\n",
      "**2. ê°œì¸ì •ë³´ ë…¸ì¶œ í”¼í•´ ì˜ˆë°©:**\n",
      "\n",
      "* ë…¸ì¶œëœ ì¸ì¦ë²ˆí˜¸ì˜ ì‚¬ìš©ì²˜ê°€ ì–´ë””ì¸ì§€ì— ë”°ë¼ ê°œì¸ì •ë³´ ë…¸ì¶œ í”¼í•´ ìƒí™©ì´ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ëª…ì˜ë„ìš© ìœ ë¬´ í™•ì¸ë°©ë²• 1ë²ˆ~3ë²ˆê¹Œì§€ ì¡°ì¹˜í•˜ì—¬ íŒŒì•…í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "* ì¶”í›„ ì¼ì–´ë‚  ìˆ˜ ìˆëŠ” 2ì°¨í”¼í•´ ì˜ˆë°©ì„ ìœ„í•´ ëª…ì˜ë„ìš© ì˜ˆë°©ë²• 1ë²ˆ ~ 4ë²ˆê¹Œì§€ ì¡°ì¹˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "**3. í•´ê²° ë°©ì•ˆ:**\n",
      "\n",
      "* ë¬¸ìì— í¬í•¨ëœ ì „í™”ë²ˆí˜¸ë¡œ ì—°ë½í•˜ê²Œ í•˜ì—¬ ê°œì¸ì •ë³´ë¥¼ íƒˆì·¨í•˜ê±°ë‚˜ ì•…ì„±íŒŒì¼, ì›ê²©ì œì–´ì•± ì‹¤í–‰ì„ ìœ ë„í•˜ëŠ” í˜•ì‹ì˜ ë³´ì´ìŠ¤í”¼ì‹±ì…ë‹ˆë‹¤.\n",
      "* í˜„ì¬ ê²€ì°°ì²­, ê¸ˆê°ì› ë“±ì˜ ê³µê³µê¸°ê´€ ëŒ€í‘œë²ˆí˜¸ë¡œ ì „í™”ë¥¼ ìˆ˜ì‹ í•˜ê³  ì†Œì† ê³µë¬´ì›ì„ ì‚¬ì¹­í•˜ëŠ” ì „í™”ë¥¼ ë°›ìœ¼ì…¨ë‹¤ë©´ ì´ë¯¸ íœ´ëŒ€í°ì€ ì›ê²©ì œì–´ ë° ì•…ì„±ì•±ì˜ ì˜í–¥ì„ ë°›ì•„ ì •ìƒì ì¸ ì „í™”ë¥¼ ìˆ˜ì‹ , ë°œì‹ í•  ìˆ˜ ìˆëŠ” ìƒíƒœê°€ ì•„ë‹ˆë¯€ë¡œ ì‹ ì†íˆ íœ´ëŒ€í°ì„ ë¹„í–‰ê¸°ëª¨ë“œ ë° ë°ì´í„°ì°¨ë‹¨, ì™€ì´íŒŒì´ ì°¨ë‹¨ ëª¨ë“œë¡œ ì „í™˜í•˜ì‹œê³ ì•…ì„±ì„¤ì¹˜íŒŒì¼(.apk) ìœ ë¬´ë¥¼ í™•ì¸ ë° ì‚­ì œ, ëª¨ë°”ì¼ ë°±ì‹  ê²€ì‚¬ë¥¼ í•´ì•¼í•©ë‹ˆë‹¤.\n",
      "* ì¶”ê°€ì ì¸ ê¸ˆì „í”¼í•´ê°€ ë°œìƒí•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì´ìš©í•˜ëŠ” ì€í–‰ì˜ ì§€ê¸‰ì •ì§€ ì½œì„¼í„°ë¡œ ë‚´ê³„ì¢Œ ì¼ê´„ ì§€ê¸‰ì •ì§€ë¥¼ ì‹ ì²­í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "* ì†Œì•¡ê²°ì œ í”¼í•´ì•¡ì— ëŒ€í•´ì„œëŠ” ê°€ê¹Œìš´ ê´€í• ê²½ì°°ì„œ ë¯¼ì›ì‹¤ì— ì‚¬ê±´ì ‘ìˆ˜ë¥¼ í•´ì£¼ì…”ì•¼ í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Ollama ë¡œì»¬ LLM ì¤€ë¹„\n",
    "chat_llm = ChatOllama(\n",
    "    model=\"gemma:7b-instruct-q4_K_M\",  # ollama listì— ìˆëŠ” ì´ë¦„ ê·¸ëŒ€ë¡œ\n",
    "    temperature=0.2,\n",
    ")\n",
    "\n",
    "def rag_answer_ollama_langchain(query: str, k: int = 5, threshold: float = 0.8) -> str:\n",
    "    # 1) ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰ (ì½”ì‚¬ì¸ ì ìˆ˜ í¬í•¨)\n",
    "    results = vectorstore.similarity_search_with_score(query, k=k)\n",
    "\n",
    "    # 2) í”„ë¡¬í”„íŠ¸ ìƒì„± (threshold ì´ìƒë§Œ ì»¨í…ìŠ¤íŠ¸ë¡œ í¬í•¨)\n",
    "    prompt = build_prompt(query, results, threshold=threshold)\n",
    "\n",
    "    # 3) LLM í˜¸ì¶œ\n",
    "    msg = chat_llm.invoke([HumanMessage(content=prompt)])\n",
    "    return getattr(msg, \"content\", str(msg))\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ\n",
    "query = \"í•´ì™¸ë°œì‹ ìœ¼ë¡œ ì¹´ë“œê°€ ë°œê¸‰ëë‹¤ëŠ” ë¬¸ìë¥¼ ìˆ˜ì‹ í–ˆëŠ”ë° ë³¸ì¸ì´ ì‹ ì²­í•˜ì§€ ì•Šì•˜ì„ ê²½ìš° ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?\"\n",
    "answer = rag_answer_ollama_langchain(query, k=5, threshold=0.8)\n",
    "print(\"[ë‹µë³€]\\n\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349ba6a5-3145-4c89-8d17-512a100e261b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Practice_rag)",
   "language": "python",
   "name": "practice_rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
